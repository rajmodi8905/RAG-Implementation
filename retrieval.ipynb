{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2aff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import langchain\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80fc5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No API key needed for Ollama (runs locally)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e721c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"phi3:mini-128k\",  # Using phi3 mini model with 128k context window\n",
    "    temperature=0.7,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e64255",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a helpful RAG (Retrieval-Augmented Generation) assistant. Answer the user's question using only the information provided in the context below. If the answer cannot be found in the context, politely indicate that you do not have enough information.\n",
    "Always cite facts, avoid speculation, and do not use any knowledge beyond what is provided in the context.\"\"\"),\n",
    "        (\"user\", \"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer based on the context above:\"\"\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c3ff7",
   "metadata": {},
   "source": [
    "### (1) Load PDF data\n",
    "\n",
    "You can either:\n",
    "- Load a single PDF: Use `PyPDFLoader(\"path/to/file.pdf\")`\n",
    "- Load multiple PDFs from a directory: Use `DirectoryLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55fa0ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18 pages from PDF(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Load a single PDF file\n",
    "# loader = PyPDFLoader(\"path/to/your/file.pdf\")\n",
    "# data = loader.load()\n",
    "\n",
    "# Option 2: Load all PDFs from a directory\n",
    "loader = DirectoryLoader(\n",
    "    \"data/\",  # Directory containing your PDF files\n",
    "    glob=\"**/*.pdf\",  # Pattern to match PDF files\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "data = loader.load()\n",
    "print(f\"Loaded {len(data)} pages from PDF(s)\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51a5bd",
   "metadata": {},
   "source": [
    "### (2) Split data to create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "054a6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "\n",
    "# As data is of type documents we can directly use split_documents over split_text in order to get the chunks.\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "379e3d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "637ee7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'macOS Version 15.6.1 (Build 24G90) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20250918101353Z00'00'\", 'moddate': \"D:20250918101353Z00'00'\", 'source': 'data\\\\Class notes, Session 10.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1'}, page_content='Class notes: Session 10 | Introduction to Philosophy HS 221 Thought Experiments on Perception and Reality One of the central discussions in Session 11 revolved around thought experiments that question the relationship between the world and human perception. The “falling tree in a forest” problem is the most famous of these. If a tree falls in a dense forest and no one is around to hear it, does it make a sound? Physically, we can define sound as vibrations traveling through a medium—air pressure waves that ripple outward. But sound as an experience requires an organism with an auditory system and a brain to interpret those vibrations. Without a subject, there are only waves, not sound. This distinction highlights the difference between the physical world and the experiential world. The question mirrors debates in philosophy since George Berkeley’s idealism, which proposed that existence itself is dependent on perception—“to be is to be perceived.” If perception creates reality, then')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35a876",
   "metadata": {},
   "source": [
    "### (3) Create embeddings for these chunks and save them to ChromaDB\n",
    "\n",
    "ChromaDB will store the embeddings persistently on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create ChromaDB vector store with persistent storage\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",  # Directory to persist the database\n",
    "    collection_name=\"pdf_collection\"   # Name for this collection\n",
    ")\n",
    "\n",
    "print(f\"✅ Created ChromaDB with {len(docs)} document chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9686c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB automatically persists to disk, no need for pickle!\n",
    "# The database is stored in ./chroma_db directory\n",
    "print(\"✅ ChromaDB is automatically persisted to ./chroma_db directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688dc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing ChromaDB from disk (if it exists)\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"./chroma_db\"):\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"pdf_collection\"\n",
    "    )\n",
    "    print(\"✅ Loaded existing ChromaDB from disk\")\n",
    "else:\n",
    "    print(\"⚠️ No existing ChromaDB found. Please run the cell above to create it.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783b694",
   "metadata": {},
   "source": [
    "### 🔍 Test Similarity Search\n",
    "\n",
    "Let's see which chunks are being retrieved with our similarity threshold!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the similarity search to see what chunks are retrieved\n",
    "test_query = \"what is the document about?\"\n",
    "\n",
    "# Perform similarity search with scores\n",
    "results_with_scores = vectorstore.similarity_search_with_score(\n",
    "    test_query,\n",
    "    k=3  # Get top 3 chunks\n",
    ")\n",
    "\n",
    "print(f\"🔍 Query: '{test_query}'\\n\")\n",
    "print(f\"📊 Found {len(results_with_scores)} chunks with similarity >= 0.7\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "    print(f\"\\n📄 Chunk {i} | Similarity Score: {score:.4f}\")\n",
    "    print(f\"Content Preview: {doc.page_content[:200]}...\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd96296",
   "metadata": {},
   "source": [
    "### (4) Retrieve similar embeddings for a given question and call LLM to retrieve final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01f5e1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a helpful RAG (Retrieval-Augmented Generation) assistant. Answer the user's question using only the information provided in the context below. If the answer cannot be found in the context, politely indicate that you do not have enough information.\\nAlways cite facts, avoid speculation, and do not use any knowledge beyond what is provided in the context.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer based on the context above:'), additional_kwargs={})]), llm=ChatOllama(model='phi3:mini-128k', temperature=0.7), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001ECAE878D60>, search_kwargs={}))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Create retriever with similarity search\n",
    "# k=3 means retrieve top 3 most similar chunks\n",
    "# score_threshold=0.7 means only return chunks with similarity score >= 0.7\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 3,                    # Return top 3 chunks\n",
    "        \"score_threshold\": 0.7     # Only chunks with similarity >= 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" means put all retrieved docs into the prompt\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}  # Uses your custom prompt!\n",
    ")\n",
    "\n",
    "print(\"✅ RAG chain created with similarity search (k=3, threshold=0.7)\")\n",
    "chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c2e228b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gen(query):\n",
    "    langchain.debug=False\n",
    "    return chain({\"query\": query}, return_only_outputs=True)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790bf75",
   "metadata": {},
   "source": [
    "### 📺 Streaming Functions\n",
    "\n",
    "You now have **three ways** to get answers from your RAG bot:\n",
    "\n",
    "1. **`gen(query)`** - Standard (waits for complete response)\n",
    "   - Returns the full answer after generation is complete\n",
    "   - Good for simple use cases\n",
    "\n",
    "2. **`gen_stream(query)`** - Basic streaming\n",
    "   - Prints text as it's generated using built-in callback\n",
    "   - Uses `StreamingStdOutCallbackHandler`\n",
    "\n",
    "3. **`gen_stream_advanced(query)`** - Advanced streaming ⭐ Recommended\n",
    "   - Custom callback for better Jupyter notebook integration\n",
    "   - Shows \"🤖 Answer:\" prefix for better formatting\n",
    "   - Most interactive experience!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d22375f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming version - prints text as it's generated\n",
    "def gen_stream(query):\n",
    "    \"\"\"\n",
    "    Stream the response token by token as the model generates it.\n",
    "    \"\"\"\n",
    "    from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "    \n",
    "    # Create retriever with same settings\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": 3, \"score_threshold\": 0.7}\n",
    "    )\n",
    "    \n",
    "    # Create a new chain with streaming enabled\n",
    "    streaming_chain = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOllama(model=\"phi3:mini-128k\", temperature=0.7, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt_template}\n",
    "    )\n",
    "    \n",
    "    print(\"Answer: \", end=\"\", flush=True)\n",
    "    result = streaming_chain({\"query\": query}, return_only_outputs=True)['result']\n",
    "    print(\"\\n\")  # Add newline after streaming\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28bfb002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: TheThe document document appears to appears to be a be a detailed summary detailed summary or trans or transcriptcript from from Session  Session 77,, titled \" titled \"IntroductionIntroduction to to Philosophy Philosophy H HSS  222211,\",\" of of an under an undergradgraduateuate course course at at a a technical inst technical instituteitute.. The The session covers session covers various various philosoph philosophicalical concepts concepts related related to to per perceptionception,, reality reality,, and and existence existence by by expl exploring theoring the distin distinctionsctions between between syntax syntax ( (structstructuralural naming naming)) and and ont ontologyology ( (actualactual existence). existence). It It discusses discusses classical classical deb debates onates on Form Formss versus versus empirical empirical realities realities in Pl in Platoato's's philosophy and modern philosophy and modern logical consist logical consistencyency as as discussed discussed by by W W..VV..O.O. Qu Quine.ine. The The conversation conversation also also touch toucheses upon upon script scripturesures,, interpre interpretingting them them crit criticallyically rather rather than than accepting accepting pass passagesages at face at face value to value to avoid avoid moral rational moral rationalizationsizations that that can can justify justify wrong wrongdoingdoing under under the the gu guiseise of of r righighteteousousnessness.. Furthermore, Furthermore, it it exam examinesines herm hermeneuteneuticsics—the—the interpretation interpretation theory emphas theory emphasizingizing historical historical context and context and bi biases inases in understanding texts understanding texts like like religious religious script scriptures.ures. The The session session con concludescludes with with a discussion a discussion on philosoph on philosophicalical interpret interpretationsations using using examples examples from from Christian Christianityity (B (Bibleible),), H Hinduinduismism ( (BBhhagagavavad Gad Gitaita),), and and Islam ( Islam (QQur'ur'anan)) to to illustrate illustrate how how them themeses of of war war rec recur,ur, raising raising questions questions about about violence, violence, righ righteteousousnessness,, per perceptionception, reality, reality,, dign dignityity,, de dehumanizationhumanization, truth, truthful social recognitionful social recognition,, and and justice. justice. The session The session a aims toims to connect met connect metaphaphysysicalical inqui inquiries withries with eth ethicalical consider considerationsations within within the context the contextss provided provided by by script scripturesures while while eng engagingaging students students'' critical critical facult facultiesies through through philosoph philosophicic disc discourse onourse on religion religion,, existence existence,, language language structure structure ( (syntaxsyntax versus versus ontology ontology),), interpretation interpretation responsibility responsibility,, and rational and rationalizationsizations for for moral moral actions as actions as related related to to religious religious texts. texts.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The document appears to be a detailed summary or transcript from Session 7, titled \"Introduction to Philosophy HS 221,\" of an undergraduate course at a technical institute. The session covers various philosophical concepts related to perception, reality, and existence by exploring the distinctions between syntax (structural naming) and ontology (actual existence). It discusses classical debates on Forms versus empirical realities in Plato\\'s philosophy and modern logical consistency as discussed by W.V.O. Quine. The conversation also touches upon scriptures, interpreting them critically rather than accepting passages at face value to avoid moral rationalizations that can justify wrongdoing under the guise of righteousness. Furthermore, it examines hermeneutics—the interpretation theory emphasizing historical context and biases in understanding texts like religious scriptures. The session concludes with a discussion on philosophical interpretations using examples from Christianity (Bible), Hinduism (Bhagavad Gita), and Islam (Qur\\'an) to illustrate how themes of war recur, raising questions about violence, righteousness, perception, reality, dignity, dehumanization, truthful social recognition, and justice. The session aims to connect metaphysical inquiries with ethical considerations within the contexts provided by scriptures while engaging students\\' critical faculties through philosophic discourse on religion, existence, language structure (syntax versus ontology), interpretation responsibility, and rationalizations for moral actions as related to religious texts.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test streaming - watch the text appear word by word!\n",
    "gen_stream(\"what is the document about ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "155eb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced streaming with custom callback (better for notebooks)\n",
    "import sys\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    \"\"\"Custom callback handler for streaming output in Jupyter notebooks.\"\"\"\n",
    "    \n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        \"\"\"Print each new token as it's generated.\"\"\"\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "def gen_stream_advanced(query):\n",
    "    \"\"\"\n",
    "    Stream the response with a custom callback handler.\n",
    "    This version works better in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    # Create retriever with same settings\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": 3, \"score_threshold\": 0.7}\n",
    "    )\n",
    "    \n",
    "    # Create streaming LLM with custom callback\n",
    "    streaming_llm = ChatOllama(\n",
    "        model=\"phi3:mini-128k\", \n",
    "        temperature=0.7, \n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()]\n",
    "    )\n",
    "    \n",
    "    # Create chain with streaming LLM\n",
    "    streaming_chain = RetrievalQA.from_chain_type(\n",
    "        llm=streaming_llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt_template}\n",
    "    )\n",
    "    \n",
    "    print(\"🤖 Answer: \", end=\"\", flush=True)\n",
    "    result = streaming_chain({\"query\": query}, return_only_outputs=True)['result']\n",
    "    print(\"\\n\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d9864aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Answer: TheThe document document appears to appears to be be from from Session Session 7 7 | | Introduction Introduction to to Philosoph Philosophyy H HSS  222121,, where where it it opens opens with with a a found foundational distinctionational distinction between between syntax syntax and ont and ontologyology.. The The session session also also touches touches upon upon various various philosoph philosophicalical them themeses such as such as script scriptureure interpretation within interpretation within cultural bi cultural biasesases, the, the relationship between relationship between per perception andception and reality reality in in understanding understanding dign dignityity,, religion religion''s connections connection to to existence through existence through logical logical f fallaallaciescies like like cheating cheating for r for righighteousteousnessness,, and and historical historical debates debates on on interpre interpretingting texts texts without bias without bias.. Additionally Additionally,, it it briefly mentions briefly mentions the the ont ontological argumentological argument for for God God’’ss existence existence as as a philosoph a philosophical conceptical concept discussed discussed during during this this session session.. The The aim seems aim seems to be to be introdu introducingcing students students to to fundamental fundamental concepts concepts in in philosophy philosophy related related to language to language ( (syntax),syntax), reality reality ( (ontontologyology),), mor moralityality,, religion religion,, and and interpretation interpretation of script of scripturesures..\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The document appears to be from Session 7 | Introduction to Philosophy HS 221, where it opens with a foundational distinction between syntax and ontology. The session also touches upon various philosophical themes such as scripture interpretation within cultural biases, the relationship between perception and reality in understanding dignity, religion's connection to existence through logical fallacies like cheating for righteousness, and historical debates on interpreting texts without bias. Additionally, it briefly mentions the ontological argument for God’s existence as a philosophical concept discussed during this session. The aim seems to be introducing students to fundamental concepts in philosophy related to language (syntax), reality (ontology), morality, religion, and interpretation of scriptures.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test advanced streaming - better output formatting\n",
    "gen_stream_advanced(\"what is the document about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5884731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document appears to be a collection of session notes from an Introduction to Philosophy course, specifically Session 7 in Week 2 (HSTS 221), titled \"Syntax to Ontology.\" The session discusses fundamental philosophical concepts such as syntax and ontology. Syntax refers to the structural or linguistic aspect of naming without establishing real existence, while ontology deals with questions about being and what exists in reality. This distinction is related to classical debates between Plato's Forms and contemporary philosophy that emphasizes logical criteria for existence.\n",
      "\n",
      "The session also touches on how language can obscure meaning through examples like the word \"ghost\" or saying, “God exists.” The instructor encourages critical thinking in interpreting scriptures rather than blind reliance due to their potential misinterpretation and historical context-dependence as noted by philosophers Paul Ricoeur and Hans-Georg Gadamer.\n",
      "\n",
      "Moreover, the discussion extends into ethical considerations involving actions like cheating justified through religious texts. This leads to a broader conversation about interpretive responsibility when reading scriptures or anything else that requires interpretation. The importance of self-examination in understanding one's biases and purposes is highlighted as part of this hermeneutical principle: meaning between text and interpreter is negotiated, not fixed.\n",
      "\n",
      "Lastly, the document mentions a brief introduction to Kant’s ontological argument for God's existence based on pure reasoning rather than empirical evidence but does not delve into details within these few lines provided from Session 7 notes.\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"what is the document about?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ba224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b36c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
